# 集成学习 (Ensemble Learning)
以下内容基于周志华老师的机器学习第8章归纳整理。

## 1 个体与集成
集成学习就是先产生一组个体学习器，然后再用某种策略将它们结合起来。

同质集成中使用一样的基学习器，比如全是决策树。异质集成就是使用了不同的组件学习器，比如决策树和神经网络。

当学习器间存在强依赖关系、必须串行生成的序列方法是Boosting。当学习器间不存在强依赖关系、可同时生成的并行化方法是Bagging和随机森林(Random Forest)。

## 2 Boosting


## 面试问题

## References
